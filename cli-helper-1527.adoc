# TXC 2024 - Lab 1518 Helper Commands
//++++
//<link rel="stylesheet"  href="http://cdnjs.cloudflare.com/ajax/libs/font-awesome/3.1.0/css/font-awesome.min.css">
//++++
:icons: font
:source-language: shell
:numbered:
// Activate experimental attribute for Keyboard Shortcut keys
:experimental:
:source-highlighter: pygments
:sectnums:
:sectnumlevels: 6
:toc: left
:toclevels: 4

## Introduction

### About this Lab

### High Level Architecture

### Accessing your Lab environment

Accessing your Lab Workstation (the physical laptop) via ssh:

[source, shell]
----
export USERNAME={your_username}
export USERIP={your_public_ip}
chmod 0600 ~/Downloads/ssh_private_key.pem
ssh -i ~/Downloads/ssh_private_key.pem -p 2223 ${USERNAME}@${USERIP}
----

Accessing your Workstation (the physical laptop) using a browser via CLI

**Windows:**

[source, shell]
----
cmd.exe
set USERIP={your_public_ip}
start https://${your_public_ip}
----

**MacOS/Linux:**

[source, shell]
----
set USERIP={your_public_ip}
open -a "Google Chrome" "https://${USERIP}"
open -a "Safari" "https://${USERIP}"
----

## IBM Storage Ceph configuration using the Dashboard

### Introduction

### Connect to the Jump Workstation Desktop

### Set the admin password

### Expand the cluster

### Add Node Labels

[source, shell]
----
grep node1 /etc/hosts | awk '{ print $2 }' | sed -e 's/node1-/node[2-4]-/g'
----

### Add Drives/OSDs to the Cluster

### Accept Grafana Self-Signed Cert to view performance details

.Generate URL for Certificate exception
[source, shell]
----
grep node1 /etc/hosts | awk '{ print $2 }'| sed -e 's#ceph-node1-#https://ceph-node1-#g' | sed -e 's/$/:3000/'
----

## Configuring Services

### Label hosts for specific services

### Service Creation

#### Edit Grafana Service

#### RGW Service Creation

#### NFS Service Creation

### Configure Storage

#### RADOS Gateway Pool Creation

#### Ceph File System Configuration

### Configure S3 User and S3 Bucket

#### Create S3 User

#### Create S3 Bucket

### Create NFS Export for a CephFS Directory

### Create NFS Export for a S3 Bucket

## Use Cases

### Object Use Case

#### Install AWS CLI

[source, shell]
----
sudo dnf install awscli -y
----

#### Configure AWS CLI

.Extract Autogenerated access and secret keys
[source, shell]
----
ssh ceph-node1 sudo radosgw-admin user info --uid=labuser | jq -r '.keys[0] | .access_key, .secret_key'
----

#### Using AWS Client

.Configure keys to use
[source, shell]
----
export AKEY=$(ssh ceph-node1 sudo radosgw-admin user info --uid=demouser | jq -r '.keys[0].access_key');echo $AKEY
export SKEY=$(ssh ceph-node1 sudo radosgw-admin user info --uid=demouser | jq -r '.keys[0].secret_key');echo $SKEY
aws configure set aws_access_key_id $AKEY --profile demouser 
aws configure set aws_secret_access_key $SKEY --profile demouser 
----

.Configure endpoint specifics
[source, shell]
----
aws configure set endpoint_url http://ceph-node4 --profile demouser 
aws configure set region multizg --profile demouser
aws configure set ca_bundle ${HOME}/rootCA.pem  --profile demouser
----

.Create an easy alias
[source, shell]
----
alias aws="aws --profile demouser"
----

.1.  List available buckets
[source, shell]
----
aws s3 ls
----

.2. Create a 10MiB file and upload it to the bucket
[source, shell]
----
truncate -s 10M 10MB.bin
aws --acl=public-read-write s3 cp ./10MB.bin s3://demo-bucket/10MB.bin 
----

.3. Get a bucket listing to view the test object. Download the object to a local file
[source, shell]
----
aws s3 ls s3://demo-bucket
aws s3 cp s3://demo-bucket/10MB.bin GET-10MB.bin
----

.4. Verify the data integrity
[source, shell]
----
echo $(openssl dgst -md5 ./10MB.bin | awk '{print $2}');echo $(openssl dgst -md5 ./GET-10MB.bin | awk '{print $2}')
----

### NFS Access

#### Mount /nfs export

.1. Change user to root
[source, shell]
----
sudo -i
----

.2. Create directory for mountpoint
[source, shell]
----
mkdir -p /mnt/nfs-cephfs
----

.3. Mount the CephFS NFS export
[source, shell]
----
mount -t nfs -o vers=4.1,port=2049 ceph-node3:/nfs /mnt/nfs-cephfs
----

.4. Get a listing of the files in the new mountpoint
[source, shell]
----
ls -al /mnt/nfs-cephfs
----

.5. Use the touch command to create an empty file
[source, shell]
----
touch /mnt/nfs-cephfs/nfsfile
----

.6. Get a listing of the files in the new mountpoint
[source, shell]
----
ls -al /mnt/nfs-cephfs
----

#### Mount /demo-bucket export

.1. Create directory for mountpoint
[source, shell]
----
mkdir -p /mnt/demo-bucket
----

.2. Mount the object bucket NFS export
[source, shell]
----
mount -t nfs -o vers=4.1,port=2049 ceph-node3:/demo-bucket /mnt/demo-bucket
----

.4. Get a listing of the files in the new mountpoint
[source, shell]
----
ls -al /mnt/nfs-cephfs
----

### RBD Access

.1. Connect to one of the Ceph nodes
[source, shell]
----
ssh ceph-node1
----

.2. Create a pool to receive the virtual block
[source, shell]
----
ceph osd pool create rbd
----

.3. Assign worjkload type to the pool
[source, shell]
----
ceph osd pool application enable rbd rbd
----
 
.4. Create virtual block device then list existing block devices
[source, shell]
----
rbd create rbd/test --size=1Gi

rbd -p rbd ls
----

.5. Display information about virtual block device
[source, shell
----
rbd info rbd/test
----

.6. Map virtual block device to node
[source, shell]
----
rbd device map rbd/test
----

.7. List virtual block devices attached to the node
[source, shell]
----
rbd device list
----

.8. Format the virtual block device
[source, shell]
----
mkfs.ext4 /dev/rbd0
----

.9. Mount the file system you just created
[source, shell]
----
mkdir /mnt/myrbd
mount /dev/rbd0 /mnt/myrbd
----

.10. Write some data to the filesystem
[source, shell]
----
echo "Writing to my Ceph RBD Image" >/mnt/myrbd/test.file
dd if=/dev/zero of=/mnt/myrbd/dd.file bs=4k count=1000
----

.11. Check how the virtual block device is being used
[source, shell]
----
ls -al /mnt/myrbd

rbd du rbd/test
----

.12. Cleanup
[source, shell]
----
umount /mnt/myrbd
rbd device unmap rbd/test
rbd rm rbd/test
----

.13. Disconnect
[source, shell]
----
exit
exit
----

